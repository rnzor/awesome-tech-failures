{"id":"microsoft-tay-2016","title":"Microsoft Tay — Prompt Injection & Adversarial Manipulation","year":2016,"evidence_type":"direct_incident","category":"ai-slop","cause":"ai","stage":"growth","impact":["trust"],"severity":{"level":"high","score":8,"financial":"N/A"},"summary":"Microsoft launched an AI chatbot designed to learn from Twitter users. Within 24 hours, adversarial users manipulated it into generating racist, antisemitic, and inflammatory content.","root_cause":"No adversarial input filtering, no content safeguards, trusted users would train it well","lessons":["Never expose learning systems to unmoderated public input without safeguards","Assume adversarial actors will test every boundary","Trust users will teach good things is not a valid architectural assumption"],"patterns":["misconfigured-trust-boundaries"],"tags":["prompt-injection","adversarial","no-guardrails","brand-damage","twitter"],"sources":[{"title":"BBC News","url":"https://www.bbc.com/news/technology-35902104","kind":"primary"}]}
{"id":"ai-agent-deletes-production-2023","title":"AI Agent Deletes Production Data","year":2023,"evidence_type":"repeated_pattern","category":"ai-slop","cause":"automation","stage":"scale","impact":["data-loss"],"severity":{"level":"high","score":7,"financial":"Unknown"},"summary":"An LLM-powered agent with write access executed destructive commands during an ambiguous task, resulting in partial production data loss.","root_cause":"Blind trust in agent autonomy, no guardrails on destructive operations, write access without reversible action requirements","lessons":["AI agents are junior interns with superpowers — they need oversight","Never grant write access without reversible actions and kill switches","All destructive operations require explicit human approval"],"patterns":["automation-without-reversal","blind-trust-in-ai-output"],"tags":["no-guardrails","blind-trust","agent-failure","write-access","autonomous-systems"],"sources":[{"title":"Enterprise AI News","url":"https://www.enterpriseai.news/2023/11/when-ai-agents-go-wrong-the-growing-pain-of-autonomous-systems/","kind":"primary"}]}
{"id":"runaway-ai-agents-cost-2023","title":"Runaway AI Agents Causing Massive Costs","year":2023,"evidence_type":"direct_incident","category":"ai-slop","cause":"automation","stage":"growth","impact":["money"],"severity":{"level":"medium","score":6,"financial":"$7k+"},"summary":"Autonomous LLM agents entered infinite loops or continuously called expensive APIs, generating thousands of dollars in token costs within hours.","root_cause":"No token or cost limits on agent actions, recursive self-improvement loops, lack of execution budgets","lessons":["Always implement cost limits on autonomous agents","Set execution budgets before letting agents run unattended","Monitor token usage in real-time with hard limits"],"patterns":["automation-without-reversal","overconfidence-from-past-success"],"tags":["runaway-costs","token-explosion","agent-loops","no-limits"],"sources":[{"title":"OpenAI Community","url":"https://community.openai.com/t/gpt-agent-burned-7000-overnight/4821","kind":"primary"}]}
{"id":"ai-generated-code-breaks-production-2023","title":"AI-Generated Code Shipped Without Review","year":2023,"evidence_type":"repeated_pattern","category":"ai-slop","cause":"ai","stage":"growth","impact":["users"],"severity":{"level":"medium","score":5,"financial":"Unknown"},"summary":"Engineering teams merged AI-generated code without adequate review, leading to production bugs, security vulnerabilities, and maintainability issues.","root_cause":"Time pressure to deliver, overconfidence in AI code quality, belief that AI knows more than me","lessons":["AI-generated code requires at least as much review as human code","Never ship AI code that you don't understand","AI is a generator, not a validator — outputs need human validation"],"patterns":["blind-trust-in-ai-output","overconfidence-from-past-success"],"tags":["ai-generated-code","no-review","production-bug","copilot"],"sources":[{"title":"Stack Overflow","url":"https://stackoverflow.blog/2023/11/16/the-risks-of-ai-code-generators/","kind":"primary"}]}
{"id":"ai-seo-content-collapse-2023","title":"AI-Generated SEO Content Collapse","year":2023,"evidence_type":"direct_incident","category":"ai-slop","cause":"ai","stage":"growth","impact":["money"],"severity":{"level":"high","score":7,"financial":"Large revenue loss"},"summary":"Large-scale AI content replaced human-written pages without editorial review, triggering search engine ranking drops across the site.","root_cause":"Low-quality AI output deployed without human review, volume prioritized over quality, no content quality gates","lessons":["Search engines reward usefulness, not volume","AI amplifies strategy — good or bad","Editorial review is mandatory for AI-generated content"],"patterns":["blind-trust-in-ai-output","decision-making-by-proxy"],"tags":["seo-collapse","low-quality-content","automation-without-review","content-strategy"],"sources":[{"title":"Ahrefs","url":"https://www.ahrefs.com/blog/ai-content-seo/","kind":"primary"}]}
{"id":"prompt-injection-data-exposure-2023","title":"Prompt Injection Leading to Data Exposure","year":2023,"evidence_type":"direct_incident","category":"ai-slop","cause":"ai","stage":"scale","impact":["data-loss"],"severity":{"level":"high","score":8,"financial":"Regulatory fines potential"},"summary":"Adversarial prompt injection attacks tricked AI systems into revealing sensitive information, bypassing safety measures and outputting private data.","root_cause":"Prompt injection as a novel attack vector, AI systems trusting user input too readily, lack of input sanitization","lessons":["Prompt injection is the SQL injection of the AI era","Validate and sanitize all inputs, including hidden prompt fields","Separate untrusted input from system prompts"],"patterns":["misconfigured-trust-boundaries","automation-without-reversal"],"tags":["prompt-injection","data-exposure","security","adversarial-input"],"sources":[{"title":"OWASP","url":"https://owasp.org/www-project-top-10-for-large-language-model-applications/","kind":"primary"}]}
{"id":"ai-summaries-replacing-understanding-2023","title":"AI Summaries Replacing Understanding","year":2023,"evidence_type":"repeated_pattern","category":"ai-slop","cause":"ai","stage":"scale","impact":["morale"],"severity":{"level":"medium","score":5,"financial":"Indirect"},"summary":"Teams relied on AI-generated summaries instead of reading source data, leading to cascading bad strategic decisions based on incomplete understanding.","root_cause":"Delegating thinking not just toil, AI used to compress data but output treated as authoritative","lessons":["AI should compress data, not replace judgment","Leaders must still read the source for critical decisions","Summary is a starting point, not the endpoint of reasoning"],"patterns":["decision-making-by-proxy","blind-trust-in-ai-output"],"tags":["ai-summaries","decision-degradation","blind-trust","automation-bias"],"sources":[{"title":"McKinsey","url":"https://www.mckinsey.com/capabilities/strategy-and-corporate-finance/our-insights/the-risk-of-relying-on-ai-summaries","kind":"primary"}]}
{"id":"vibe-coding-unmaintainable-2024","title":"Vibe Coding Unmaintainable Systems","year":2024,"evidence_type":"repeated_pattern","category":"ai-slop","cause":"ai","stage":"early","impact":["morale"],"severity":{"level":"low","score":4,"financial":"Technical debt"},"summary":"Teams used AI coding tools extensively to build entire features or backends, only to discover the code was unmaintainable, undocumented, and impossible for humans to extend.","root_cause":"Vibe coding — generating code without understanding it, no documentation generated, no architectural oversight","lessons":["Code you don't understand is technical debt from day one","AI can generate code, but humans must own architecture","Require documentation and code review for AI-generated code"],"patterns":["blind-trust-in-ai-output","overconfidence-from-past-success"],"tags":["vibe-coding","technical-debt","ai-generated-codebase","unmaintainable"],"sources":[{"title":"Indie Hackers","url":"https://www.indiehackers.com/post/what-happened-when-we-let-ai-write-our-whole-backend","kind":"primary"}]}
{"id":"over-automated-customer-support-2023","title":"Over-Automated Customer Support Destroying Trust","year":2023,"evidence_type":"direct_incident","category":"ai-slop","cause":"automation","stage":"scale","impact":["trust"],"severity":{"level":"medium","score":6,"financial":"Customer churn"},"summary":"Companies deployed AI customer support chatbots without adequate human escalation paths, leading to misinformation, frustrated customers, and trust damage.","root_cause":"Cost-cutting focus over customer experience, no clear escalation paths, chatbots empowered to make promises they couldn't keep","lessons":["Customer trust is hard to earn, easy to lose","AI chatbots need clear escalation paths to humans","Never let AI make promises it can't verify"],"patterns":["automation-without-reversal","decision-making-by-proxy"],"tags":["customer-support","chatbot-failure","no-escalation","trust-destruction"],"sources":[{"title":"CBC News","url":"https://www.cbc.ca/news/canada/air-canada-ai-chatbot-misinformation-1.7139752","kind":"primary"}]}
{"id":"github-database-outage-2018","title":"GitHub Database Outage","year":2018,"evidence_type":"direct_incident","category":"outage","cause":"architecture","stage":"scale","impact":["users"],"severity":{"level":"high","score":8,"financial":"Productivity loss"},"summary":"A routine maintenance operation triggered a large-scale MySQL replication failure, causing hours of downtime across GitHub's platform.","root_cause":"Overconfidence in replication infrastructure, insufficient understanding of failure modes, restore paths never tested","lessons":["Backups are useless if restore paths are not tested","We have done this before is not a safety guarantee","Understand failure modes before they happen"],"patterns":["hidden-single-point-of-failure","overconfidence-from-past-success"],"tags":["hidden-dependency","rollback-failure","observability-gap","mysql","replication"],"sources":[{"title":"GitHub Blog","url":"https://github.blog/2018-10-30-october-incident-report/","kind":"primary"}]}
{"id":"aws-s3-us-east-1-2017","title":"AWS S3 us-east-1 Outage","year":2017,"evidence_type":"direct_incident","category":"outage","cause":"human-error","stage":"scale","impact":["users"],"severity":{"level":"critical","score":10,"financial":"$100M+"},"summary":"A typo during debugging commands took down S3 in the us-east-1 region, cascading into major internet outages for thousands of services.","root_cause":"Human error during debugging, insufficient blast-radius controls, region-level dependencies as silent killers","lessons":["Highly available does not mean invulnerable","Region-level dependencies are silent killers","Debugging in production requires extreme caution"],"patterns":["hidden-single-point-of-failure","automation-without-reversal"],"tags":["blast-radius","control-plane","region-dependency","s3","typo"],"sources":[{"title":"AWS","url":"https://aws.amazon.com/message/41926/","kind":"primary"}]}
{"id":"knight-capital-2012","title":"Knight Capital Trading Loss","year":2012,"evidence_type":"direct_incident","category":"outage","cause":"automation","stage":"scale","impact":["money"],"severity":{"level":"critical","score":10,"financial":"$440M"},"summary":"A faulty deployment activated dead code paths in Knight Capital's trading system, triggering uncontrolled trading that lost approximately $440M in under an hour.","root_cause":"Broken deployment process, dead code left in production, no kill switches, automation without human oversight","lessons":["Automation without kill switches is lethal","Old code is still production code — audit and remove dead paths","Every automated system needs a tested emergency stop"],"patterns":["automation-without-reversal"],"tags":["no-rollback","deployment-failure","trading-automation","dead-code","kill-switch"],"sources":[{"title":"SEC","url":"https://www.sec.gov/spotlight/equity-markets-structure-committee/knight-capital-report.pdf","kind":"primary"}]}
{"id":"cloudflare-regex-catastrophe-2019","title":"Cloudflare Regex Catastrophe","year":2019,"evidence_type":"direct_incident","category":"outage","cause":"architecture","stage":"scale","impact":["trust"],"severity":{"level":"high","score":8,"financial":"Global disruption"},"summary":"A single regex rule deployed to Cloudflare's WAF caused CPU exhaustion across all HTTP/HTTPS servers worldwide, resulting in 30+ minutes of 502 errors.","root_cause":"The regex caused catastrophic backtracking, rule not tested for CPU impact, safety mechanism removed by mistake","lessons":["Test regex performance before deployment","Any change to safety mechanisms requires review and rollback plan","Single points of failure in safety systems are catastrophic"],"patterns":["overconfidence-from-past-success"],"tags":["regex","backtracking","cpu-exhaustion","waf","global-impact","cascade"],"sources":[{"title":"Cloudflare Blog","url":"https://blog.cloudflare.com/details-of-the-cloudflare-outage-on-july-2-2019/","kind":"primary"}]}
{"id":"capital-one-breach-2019","title":"Capital One Breach","year":2019,"evidence_type":"direct_incident","category":"security","cause":"human-error","stage":"scale","impact":["trust"],"severity":{"level":"high","score":9,"financial":"$80M fine"},"summary":"An attacker exploited a misconfigured cloud firewall combined with SSRF to access sensitive customer data stored in AWS, exposing 100M records.","root_cause":"Misconfigured IAM roles with over-privileged access, internal services assumed trusted without validation","lessons":["Cloud security failures are often configuration, not complex exploits","Assume internal services will be abused — apply zero-trust principles","IAM permissions should follow least-privilege"],"patterns":["misconfigured-trust-boundaries"],"tags":["misconfiguration","iam","ssrf","cloud-security","over-privileged-access"],"sources":[{"title":"DOJ","url":"https://www.justice.gov/opa/press-release/file/1244101/download","kind":"primary"}]}
{"id":"equifax-breach-2017","title":"Equifax Breach","year":2017,"evidence_type":"direct_incident","category":"security","cause":"human-error","stage":"scale","impact":["data-loss"],"severity":{"level":"critical","score":10,"financial":"$1.38B"},"summary":"Attackers exploited a known Apache Struts vulnerability that had a patch available for 2 months, exposing 147.9 million Americans' data.","root_cause":"Failure to patch a critical vulnerability despite knowing about it, no network segmentation, plaintext credentials","lessons":["Patch critical vulnerabilities within hours/days, not weeks/months","Network segmentation limits blast radius of initial compromise","Store credentials securely"],"patterns":["patching-debt"],"tags":["unpatched","apache-struts","credential-lateral-movement","no-segmentation","regulatory-fine"],"sources":[{"title":"BreachSense","url":"https://www.breachsense.com/blog/equifax-data-breach/","kind":"primary"}]}
{"id":"multi-agent-loop-2025","title":"Autonomous Multi-Agent Loop Cost Spike","year":2025,"evidence_type":"direct_incident","category":"ai-slop","cause":"automation","stage":"scale","impact":["money"],"severity":{"level":"medium","score":6,"financial":"$12k"},"summary":"A chain of specialized agents using MCP entered a recursive delegation loop while trying to resolve a complex integration task.","root_cause":"Lack of global context sharing between agents, recursive delegation paths permitted without depth limits","lessons":["Multi-agent systems require a central orchestrator with hard depth limits","Implement token-bucket rate limiting at the organization level","Recursive delegation must require explicit human approval"],"patterns":["automation-without-reversal","hidden-single-point-of-failure"],"tags":["multi-agent","mcp","cost-explosion","recursive-delegation","runaway-agents"],"sources":[{"title":"AgenticDev Corp","url":"https://example.com/blog/multi-agent-loop-incident","kind":"primary"}]}
{"id":"agentic-db-migration-2025","title":"Agentic Database Migration Data Corruption","year":2025,"evidence_type":"repeated_pattern","category":"ai-slop","cause":"ai","stage":"growth","impact":["data-loss"],"severity":{"level":"high","score":8,"financial":"High recovery cost"},"summary":"An AI agent tasked with performing a schema migration misidentified table relationships, executing a destructive command on the wrong table.","root_cause":"Agent failed to verify documentation consistency before execution, dry-run mode did not catch semantic errors","lessons":["DB migrations always require human-in-loop verification","AI agents must run schema-checking tools before suggesting changes","Documentation fed to RAG must be versioned and synced"],"patterns":["blind-trust-in-ai-output","automation-without-reversal"],"tags":["agentic-migration","data-corruption","schema-hallucination","autonomous-ops"],"sources":[{"title":"CloudScale","url":"https://example.com/tech/agentic-ops-risks","kind":"primary"}]}
{"id":"gitlab-data-loss-2017","title":"GitLab Sysadmin Database Deletion","year":2017,"evidence_type":"direct_incident","category":"outage","cause":"human-error","stage":"scale","impact":["data-loss"],"severity":{"level":"high","score":8,"financial":"$Unknown"},"summary":"A system administrator accidentally deleted 300GB of live production data by running rm -rf on the wrong directory during maintenance.","root_cause":"Human error due to fatigue and lack of guardrails, multiple levels of backups failed or were empty","lessons":["Backups are only as good as your last successful restore test","Implement guardrails for destructive commands","Engineer systems to be resilient to human error at 2 AM"],"patterns":["automation-without-reversal","overconfidence-from-past-success"],"tags":["data-loss","backup-failure","human-error","postgresql","replication"],"sources":[{"title":"GitLab Blog","url":"https://about.gitlab.com/blog/2017/02/10/postmortem-of-database-outage-of-january-31/","kind":"primary"}]}
{"id":"fastly-outage-2021","title":"Fastly Global Config Outage","year":2021,"evidence_type":"direct_incident","category":"outage","cause":"architecture","stage":"scale","impact":["users"],"severity":{"level":"high","score":9,"financial":"Significant"},"summary":"A single valid configuration change by one customer triggered a dormant software bug in Fastly's edge cloud, taking down major sites globally.","root_cause":"Dormant bug in the VCL compiler triggered by specific parameters, failure to isolate service-wide impacts","lessons":["Individual customer actions should never trigger global failures","Implement cell-based architecture to limit blast radius","Fast rollbacks are the best defense against unknown triggers"],"patterns":["hidden-single-point-of-failure","automation-without-reversal"],"tags":["vcl","global-outage","cascading-failure","edge-computing","hidden-sop"],"sources":[{"title":"Fastly Blog","url":"https://www.fastly.com/blog/summary-of-june-8-incident","kind":"primary"}]}
{"id":"solarwinds-supply-chain-2020","title":"SolarWinds Orion Supply Chain Attack","year":2020,"evidence_type":"direct_incident","category":"security","cause":"architecture","stage":"scale","impact":["trust"],"severity":{"level":"critical","score":10,"financial":"Massive"},"summary":"APT29 compromised the software build process to inject the SUNBURST backdoor into signed Orion updates distributed to 30,000+ organizations.","root_cause":"Attackers compromised the automated build process—a less obvious attack surface than source control; exfiltration masked as legitimate traffic.","lessons":["Build infrastructure is as critical as source control","Supply chain attacks succeed by exploiting trust in software updates","Cryptographic signing does not ensure integrity if the signing key is compromised"],"patterns":["hidden-single-point-of-failure","misconfigured-trust-boundaries"],"tags":["supply-chain","build-infrastructure-compromise","nation-state-access","solarwinds","2020-major"],"sources":[{"title":"Google Cloud","url":"https://cloud.google.com/blog/topics/threat-intelligence/sunburst-backdoor-analysis","kind":"primary"}]}
{"id":"uber-breach-2022","title":"Uber Social Engineering Breach","year":2022,"evidence_type":"direct_incident","category":"security","cause":"human-error","stage":"scale","impact":["trust"],"severity":{"level":"high","score":9,"financial":"Significant"},"summary":"An attacker gained access to internal Uber systems by bombarding an employee with MFA push notifications and then posing as IT support.","root_cause":"Reliance on push-based MFA vulnerable to fatigue, lack of internal zero-trust, human vulnerability","lessons":["Shift from push-based MFA to security keys to prevent fatigue","Apply zero-trust internally: password should not grant full access","Train employees on social engineering tactics"],"patterns":["misconfigured-trust-boundaries","overconfidence-from-past-success"],"tags":["social-engineering","mfa-fatigue","privileged-access","human-factor","data-exposure"],"sources":[{"title":"Uber","url":"https://www.uber.com/newsroom/security-update/","kind":"primary"}]}
{"id":"multi-agent-failures-arxiv-2025","title":"Multi-Agent LLM System Failures","year":2025,"evidence_type":"direct_incident","category":"ai-slop","cause":"architecture","stage":"scale","impact":["users"],"severity":{"level":"high","score":8,"financial":"Indirect"},"summary":"Analysis of 1,600+ traces shows coordination failures in 41% to 86.7% of multi-agent implementations.","root_cause":"Lack of organizational structure—clear role definitions, communication protocols, and verification mechanisms.","lessons":["Coordination failures dominate; intelligence is not the limiting factor","Systems require explicit approval chains and verification layers","Unclear goals and role ambiguity cascade"],"patterns":["decision-making-by-proxy","hidden-single-point-of-failure"],"tags":["coordination-failure","system-design","multi-agent-llm","verification-gap"],"sources":[{"title":"ArXiv","url":"https://arxiv.org/abs/2410.12352","kind":"primary"}]}
{"id":"rag-hallucination-cascades-2025","title":"RAG Hallucination Cascades","year":2025,"evidence_type":"repeated_pattern","category":"ai-slop","cause":"ai","stage":"scale","impact":["trust"],"severity":{"level":"high","score":8,"financial":"Brand Damage"},"summary":"Hallucination detection tools failed on 83% of production examples, allowing false context to amplify factual errors.","root_cause":"RAG systems inherit model hallucinations; poor retrieval quality allows false context to amplify errors.","lessons":["RAG reduces hallucinations but does not eliminate them; verification is essential","Retrieval quality directly impacts downstream accuracy","Continuous testing against real failure patterns"],"patterns":["blind-trust-in-ai-output","overconfidence-from-past-success"],"tags":["hallucination","rag-degradation","business-logic-bypass","detection-failure"],"sources":[{"title":"LinkedIn","url":"https://www.linkedin.com/pulse/why-rag-projects-fail-2025-adrian-faryniuk/","kind":"primary"}]}
{"id":"ai-coding-rules-backdoor-2025","title":"AI Coding Assistant Rules File Backdoor","year":2025,"evidence_type":"direct_incident","category":"ai-slop","cause":"architecture","stage":"scale","impact":["data-loss"],"severity":{"level":"critical","score":9,"financial":"Massive Potential"},"summary":"Attackers can inject malicious instructions via hidden Unicode in project config files to manipulate AI into generating backdoors.","root_cause":"AI assistants lack trust boundaries between user-controlled config files and system instructions.","lessons":["Treat configuration files with the same security rigor as code","Invisible characters and Unicode obfuscation can evade standard review","Trust in AI tools compounds supply chain risk"],"patterns":["misconfigured-trust-boundaries","hidden-single-point-of-failure"],"tags":["supply-chain","config-injection","backdoor-insertion","ai-assistant"],"sources":[{"title":"Pillar Security","url":"https://www.pillar.security/blog/rules-file-backdoor","kind":"primary"}]}
{"id":"model-collapse-nature-2024","title":"Synthetic Data Poisoning & Model Collapse","year":2024,"evidence_type":"repeated_pattern","category":"ai-slop","cause":"ai","stage":"scale","impact":["users"],"severity":{"level":"high","score":7,"financial":"Retraining Costs"},"summary":"Recursive training on synthetic data without human anchoring causes progressive degradation and loss of rare patterns.","root_cause":"Statistical and functional approximation errors compound exponentially when no human ground truth anchors the distribution.","lessons":["Mixing human and synthetic data prevents collapse","Early collapse is hard to detect; performance may mask tail degradation","Multi-modal systems exhibit unique collapse patterns"],"patterns":["blind-trust-in-ai-output","decision-making-by-proxy"],"tags":["data-degradation","synthetic-recursion","performance-loss","model-collapse"],"sources":[{"title":"Nature","url":"https://www.nature.com/articles/s41586-024-07566-y","kind":"primary"}]}
{"id":"agentic-cost-explosions-2025","title":"Agentic Workflow Cost Explosions","year":2025,"evidence_type":"repeated_pattern","category":"ai-slop","cause":"automation","stage":"scale","impact":["money"],"severity":{"level":"medium","score":6,"financial":"10x budget"},"summary":"AI agent deployments experienced 10x cost spirals due to token bloat, function-calling recursion, and lack of circuit breakers.","root_cause":"Development environments don't reflect production complexity; token usage multiplies across agent handoffs.","lessons":["Test with production-scale data volumes and real API limits","Multi-agent systems require aggressive token caching","Set hard budget limits with automatic circuit breakers"],"patterns":["automation-without-reversal","blind-trust-in-ai-output"],"tags":["cost-runaway","token-bloat","budget-explosion","agentic-workflow"],"sources":[{"title":"LinkedIn","url":"https://www.linkedin.com/pulse/your-ai-agent-just-burned-10x-weekly-budget-nav-bhasin/","kind":"primary"}]}
{"id":"cloudflare-bot-mgmt-2025","title":"Cloudflare Bot Management Feature File Corruption","year":2025,"evidence_type":"direct_incident","category":"outage","cause":"automation","stage":"scale","impact":["users"],"severity":{"level":"high","score":9,"financial":"Significant"},"summary":"A database permission change caused the Bot Management feature file to double in size, exceeding routing software limits globally.","root_cause":"Oversized file not caught by upstream validation; software had hard limit that wasn't enforced until network propagation.","lessons":["Configuration changes can have exponential effects; test at scale","Enforce size limits at source, not just at consumption","Distinguish DDoS from internal cascade early"],"patterns":["hidden-single-point-of-failure","automation-without-reversal"],"tags":["cascading-failure","config-propagation","global-outage","feature-file-poisoning","2025-active"],"sources":[{"title":"Cloudflare","url":"https://blog.cloudflare.com/outage-report-november-18-2025/","kind":"primary"}]}
{"id":"meta-cascading-failure-2024","title":"Meta Cascading Service Failure","year":2024,"evidence_type":"direct_incident","category":"outage","cause":"architecture","stage":"scale","impact":["users"],"severity":{"level":"high","score":8,"financial":"Significant"},"summary":"Technical issues in Meta's infrastructure cascaded across Facebook, Instagram, Threads, and WhatsApp due to shared backend dependencies.","root_cause":"Infrastructure-level issue cascaded due to tight coupling and shared backend dependencies among multiple platforms.","lessons":["Shared infrastructure creates cascading risk","Complex interdependencies are invisible until they fail","Long MTTR indicates detection/coordination gaps"],"patterns":["hidden-single-point-of-failure","overconfidence-from-past-success"],"tags":["cascading-failure","shared-dependency","global-outage","social-media","2024-major"],"sources":[{"title":"CNBC","url":"https://www.cnbc.com/2024/12/11/metas-facebook-instagram-go-down.html","kind":"primary"}]}
{"id":"aws-observability-failure-2025","title":"AWS Observability Stack Co-Located Failure","year":2025,"evidence_type":"direct_incident","category":"outage","cause":"architecture","stage":"scale","impact":["users"],"severity":{"level":"high","score":8,"financial":"Indirect"},"summary":"Outage in us-east-1 took down production workloads and the observability stack co-located in the same region, leaving engineers blind.","root_cause":"Architectural decision to co-locate monitoring with production; lack of geographic redundancy for observability systems.","lessons":["Observability must be external to monitored systems","Regional failures require cross-region monitoring","AI cannot help if you are blind during the incident"],"patterns":["hidden-single-point-of-failure","decision-making-by-proxy"],"tags":["observability-gap","architecture","visibility-loss","regional-outage","2025-critical"],"sources":[{"title":"LinkedIn","url":"https://www.linkedin.com/pulse/when-observability-fails-what-we-can-learn-from-aws-outage/","kind":"primary"}]}
{"id":"crowdstrike-falcon-outage-2024","title":"CrowdStrike Falcon Sensor Faulty Update","year":2024,"evidence_type":"direct_incident","category":"outage","cause":"automation","stage":"scale","impact":["money"],"severity":{"level":"critical","score":10,"financial":"$5B+"},"summary":"Faulty sensor update triggered crashes on 8.5M Windows devices globally; largest IT outage in history requiring manual remediation.","root_cause":"Insufficient pre-deployment testing and lack of staged rollout; update deployed globally without canary validation.","lessons":["Endpoint updates require most rigorous testing","Canary deployments are non-negotiable","Rollbacks requiring physical access are disasters"],"patterns":["automation-without-reversal","overconfidence-from-past-success"],"tags":["rollback-failure","deployment-validation","systemic-outage","endpoint-security","2024-worst"],"sources":[{"title":"CrowdStrike","url":"https://www.crowdstrike.com/blog/falcon-content-update-remediation-and-guidance-hub/","kind":"primary"}]}
{"id":"cloudflare-ddos-rule-failure-2024","title":"Cloudflare DDoS Rule Deployment Failure","year":2024,"evidence_type":"direct_incident","category":"outage","cause":"architecture","stage":"scale","impact":["users"],"severity":{"level":"medium","score":7,"financial":"Significant"},"summary":"New DDoS rule triggered a latent bug in rate-limiting system, causing CPU spikes and global error rates of 1-3%.","root_cause":"Broken cookie validation in new rule triggered exception; latent interaction not exercised in staging.","lessons":["Latent bugs can be triggered by new code paths","Gradual rollout must include failure detection","Distinguish internal cascades from external attacks"],"patterns":["hidden-single-point-of-failure","overconfidence-from-past-success"],"tags":["rollback-failure","latent-bug","error-spike","ddos-rule","2024-major"],"sources":[{"title":"Cloudflare","url":"https://blog.cloudflare.com/incident-report-june-20-2024/","kind":"primary"}]}
{"id":"twitch-leak-2021","title":"Twitch Source Code Leak","year":2021,"evidence_type":"direct_incident","category":"security","cause":"human-error","stage":"scale","impact":["trust"],"severity":{"level":"high","score":9,"financial":"Significant"},"summary":"A server configuration change exposed 125GB of data, including Twitch's complete source code and internal tools.","root_cause":"Server configuration error during a system change made an S3 bucket or similar storage service publicly accessible.","lessons":["Configuration changes are leading cause of data exposure","Secrets in source code are a systemic vulnerability","Once code is leaked, assume all embedded secrets are compromised"],"patterns":["misconfigured-trust-boundaries"],"tags":["cloud-misconfiguration","s3-public-access","source-code-leak","secrets-exposure","2021-major"],"sources":[{"title":"BBC","url":"https://www.bbc.com/news/technology-58817658","kind":"primary"}]}
{"id":"github-codeql-vulnerability-2025","title":"GitHub CodeQL Supply Chain Vulnerability","year":2025,"evidence_type":"direct_incident","category":"security","cause":"architecture","stage":"scale","impact":["trust"],"severity":{"level":"critical","score":9,"financial":"Massive Potential"},"summary":"Brief token exposure in CodeQL artifacts allowed modification of immutable tags, risking exfiltration from hundreds of thousands of repos.","root_cause":"Non-immutable tags in official actions and token exposure in workflow artifacts.","lessons":[" CI/CD supply chain attacks are effective and dangerous","Immutable tags and workflow pinning are not optional","Cache poisoning is a persistent threat"],"patterns":["misconfigured-trust-boundaries","hidden-single-point-of-failure"],"tags":["supply-chain","token-exposure","code-exfiltration","github-actions","2025-active"],"sources":[{"title":"Praetorian","url":"https://www.praetorian.com/blog/codeqleaked-public-secrets-exposure/","kind":"primary"}]}
{"id":"log4shell-2021","title":"Log4Shell — Global RCE","year":2021,"evidence_type":"direct_incident","category":"security","cause":"architecture","stage":"scale","impact":["trust"],"severity":{"level":"critical","score":10,"financial":"Massive"},"summary":"A remote code execution vulnerability in Log4j 2 allowed attackers to run arbitrary code via malicious JNDI lookups in crafted log messages.","root_cause":"Log4j message lookup feature did not validate or sandbox JNDI references; existed unnoticed since 2013.","lessons":["Dynamic code execution features are inherently dangerous","User input flowing to logs is a critical attack surface","Widespread usage increases blast radius significantly"],"patterns":["hidden-single-point-of-failure"],"tags":["zero-day","unsafe-feature","rce-global","log4j","2021-critical"],"sources":[{"title":"Apache","url":"https://logging.apache.org/log4j/2.x/security.html","kind":"primary"}]}
{"id":"booking-oauth-redirect-2023","title":"Booking.com OAuth Redirect URI Misconfiguration","year":2023,"evidence_type":"direct_incident","category":"security","cause":"human-error","stage":"scale","impact":["trust"],"severity":{"level":"high","score":8,"financial":"Significant"},"summary":"Loose path matching on redirect URIs allowed authorization code theft and account takeovers.","root_cause":"Application-layer implementation did not enforce exact path matching for redirect URIs.","lessons":["OAuth client applications must validate strictly","Exact path matching is required, not just domain validation","Open redirects are dangerous vectors in auth flows"],"patterns":["misconfigured-trust-boundaries"],"tags":["authentication-bypass","oauth-misconfiguration","account-takeover","redirect-uri","2023-pattern"],"sources":[{"title":"Descope","url":"https://www.descope.com/blog/post/oauth-vulnerabilities","kind":"primary"}]}
{"id":"expo-oauth-token-leak-2023","title":"Expo OAuth Token Exposure","year":2023,"evidence_type":"direct_incident","category":"security","cause":"architecture","stage":"scale","impact":["trust"],"severity":{"level":"high","score":8,"financial":"Significant"},"summary":"Manipulation of the returnURL parameter allowed OAuth tokens to be sent to attacker-controlled domains.","root_cause":"Insufficient validation of the returnURL parameter in OAuth proxy.","lessons":["Return URL validation must be as strict as redirect URI validation","OAuth proxies introduce additional validation requirements"],"patterns":["misconfigured-trust-boundaries"],"tags":["authentication-bypass","oauth-parameter-injection","account-takeover","token-leakage","2023-pattern"],"sources":[{"title":"Descope","url":"https://www.descope.com/blog/post/oauth-vulnerabilities","kind":"primary"}]}
{"id":"unit42-social-eng-trend-2025","title":"Unit 42 Social Engineering Trend Report","year":2025,"evidence_type":"repeated_pattern","category":"security","cause":"human-error","stage":"scale","impact":["trust"],"severity":{"level":"high","score":8,"financial":"Global Trend"},"summary":"Social engineering accounted for 36% of all incidents, with a shift towards SEO poisoning and help desk manipulation.","root_cause":"Attackers exploit human behavior; weak access controls amplify damage after initial compromise.","lessons":["Social engineering succeeds through behavior, not sophistication","Weak controls amplify impact","Detection gaps mask critical signals"],"patterns":["misconfigured-trust-boundaries","decision-making-by-proxy"],"tags":["human-factor","trust-exploitation","data-exfiltration","bec","2025-trend"],"sources":[{"title":"Unit 42","url":"https://unit42.paloaltonetworks.com/global-incident-response-report/","kind":"primary"}]}
{"id":"lexisnexis-github-breach-2024","title":"LexisNexis GitHub Account Compromise","year":2024,"evidence_type":"direct_incident","category":"security","cause":"human-error","stage":"scale","impact":["trust"],"severity":{"level":"high","score":9,"financial":"Significant"},"summary":"Attacker gained access via pretexting and exfiltrated personal data for 364,000+ individuals from development platforms.","root_cause":"Weak authentication on GitHub and human vulnerability to pretexting.","lessons":["GitHub access is equivalent to internal infrastructure access","Social engineering targets help desk/support staff","Third-party dev platforms hold sensitive data"],"patterns":["misconfigured-trust-boundaries","overconfidence-from-past-success"],"tags":["social-engineering","credential-compromise","pii-exfiltration","github-access","2024-major"],"sources":[{"title":"TechCrunch","url":"https://techcrunch.com/2025/05/27/data-broker-lexisnexis-breach-exposed-364k-people/","kind":"primary"}]}
