{"id":"microsoft-tay-2016","title":"Microsoft Tay — Prompt Injection & Adversarial Manipulation","year":2016,"evidence-type":"direct-incident","category":"ai-slop","cause":"ai","stage":"growth","impact":["trust"],"severity":{"level":"high","score":8,"financial":"N/A"},"summary":"Microsoft launched an AI chatbot designed to learn from Twitter users. Within 24 hours, adversarial users manipulated it into generating racist, antisemitic, and inflammatory content.","root-cause":"No adversarial input filtering, no content safeguards, trusted users would train it well","lessons":["Never expose learning systems to unmoderated public input without safeguards","Assume adversarial actors will test every boundary","Trust users will teach good things is not a valid architectural assumption"],"patterns":["misconfigured-trust-boundaries"],"tags":["prompt-injection","adversarial","no-guardrails","brand-damage","twitter"],"sources":["https://www.bbc.com/news/technology-35902104","https://www.cbsnews.com/news/microsoft-shuts-down-ai-chatbot-after-it-turned-into-racist-nazi/","https://ethicsunwrapped.utexas.edu/case-study/a-i-trust-tays-trespasses"],"supporting-entities":["Microsoft","Twitter"]}
{"id":"ai-agent-deletes-production-2023","title":"AI Agent Deletes Production Data","year":2023,"evidence-type":"repeated-pattern","category":"ai-slop","cause":"automation","stage":"scale","impact":["data-loss"],"severity":{"level":"high","score":7,"financial":"Unknown"},"summary":"An LLM-powered agent with write access executed destructive commands during an ambiguous task, resulting in partial production data loss.","root-cause":"Blind trust in agent autonomy, no guardrails on destructive operations, write access without reversible action requirements","lessons":["AI agents are junior interns with superpowers — they need oversight","Never grant write access without reversible actions and kill switches","All destructive operations require explicit human approval"],"patterns":["automation-without-reversal","blind-trust-in-ai-output"],"tags":["no-guardrails","blind-trust","agent-failure","write-access","autonomous-systems"],"sources":["https://www.enterpriseai.news/2023/11/when-ai-agents-go-wrong-the-growing-pain-of-autonomous-systems/","https://news.ycombinator.com/item?id=37810234","https://www.langchain.com/blog/agent-safety-guardrails"],"supporting-entities":["LangChain","Various Engineering Teams"]}
{"id":"runaway-ai-agents-cost-2023","title":"Runaway AI Agents Causing Massive Costs","year":2023,"evidence-type":"direct-incident","category":"ai-slop","cause":"automation","stage":"growth","impact":["money"],"severity":{"level":"medium","score":6,"financial":"$7k+"},"summary":"Autonomous LLM agents entered infinite loops or continuously called expensive APIs, generating thousands of dollars in token costs within hours.","root-cause":"No token or cost limits on agent actions, recursive self-improvement loops, lack of execution budgets","lessons":["Always implement cost limits on autonomous agents","Set execution budgets before letting agents run unattended","Monitor token usage in real-time with hard limits"],"patterns":["automation-without-reversal","overconfidence-from-past-success"],"tags":["runaway-costs","token-explosion","agent-loops","no-limits"],"sources":["https://news.ycombinator.com/item?id=37291821","https://github.com/langchain-ai/langchain/issues/10453","https://community.openai.com/t/gpt-agent-burned-7000-overnight/4821"],"supporting-entities":["OpenAI","LangChain","Community Contributors"]}
{"id":"ai-generated-code-breaks-production-2023","title":"AI-Generated Code Shipped Without Review","year":2023,"evidence-type":"repeated-pattern","category":"ai-slop","cause":"ai","stage":"growth","impact":["users"],"severity":{"level":"medium","score":5,"financial":"Unknown"},"summary":"Engineering teams merged AI-generated code without adequate review, leading to production bugs, security vulnerabilities, and maintainability issues.","root-cause":"Time pressure to deliver, overconfidence in AI code quality, belief that AI knows more than me","lessons":["AI-generated code requires at least as much review as human code","Never ship AI code that you don't understand","AI is a generator, not a validator — outputs need human validation"],"patterns":["blind-trust-in-ai-output","overconfidence-from-past-success"],"tags":["ai-generated-code","no-review","production-bug","copilot"],"sources":["https://stackoverflow.blog/2023/11/16/the-risks-of-ai-code-generators/","https://news.ycombinator.com/item?id=38420156","https://www.getrevue.co/profileengineering/p/why-we-stopped-merging-ai-code-blindly"],"supporting-entities":["Stack Overflow","GitHub","Various Engineering Teams"]}
{"id":"ai-seo-content-collapse-2023","title":"AI-Generated SEO Content Collapse","year":2023,"evidence-type":"direct-incident","category":"ai-slop","cause":"ai","stage":"growth","impact":["money"],"severity":{"level":"high","score":7,"financial":"Large revenue loss"},"summary":"Large-scale AI content replaced human-written pages without editorial review, triggering search engine ranking drops across the site.","root-cause":"Low-quality AI output deployed without human review, volume prioritized over quality, no content quality gates","lessons":["Search engines reward usefulness, not volume","AI amplifies strategy — good or bad","Editorial review is mandatory for AI-generated content"],"patterns":["blind-trust-in-ai-output","decision-making-by-proxy"],"tags":["seo-collapse","low-quality-content","automation-without-review","content-strategy"],"sources":["https://developers.google.com/search/blog/2022/12/helpful-content-update","https://www.ahrefs.com/blog/ai-content-seo/","https://www.searchenginejournal.com/ai-content-seo-risks/"],"supporting-entities":["Google","Ahrefs","Search Engine Journal"]}
{"id":"prompt-injection-data-exposure-2023","title":"Prompt Injection Leading to Data Exposure","year":2023,"evidence-type":"direct-incident","category":"ai-slop","cause":"ai","stage":"scale","impact":["data-loss"],"severity":{"level":"high","score":8,"financial":"Regulatory fines potential"},"summary":"Adversarial prompt injection attacks tricked AI systems into revealing sensitive information, bypassing safety measures and outputting private data.","root-cause":"Prompt injection as a novel attack vector, AI systems trusting user input too readily, lack of input sanitization","lessons":["Prompt injection is the SQL injection of the AI era","Validate and sanitize all inputs, including hidden prompt fields","Separate untrusted input from system prompts"],"patterns":["misconfigured-trust-boundaries","automation-without-reversal"],"tags":["prompt-injection","data-exposure","security","adversarial-input"],"sources":["https://owasp.org/www-project-top-10-for-large-language-model-applications/","https://www.microsoft.com/en-us/security/blog/2023/10/understanding-prompt-injection/","https://blog.langchain.com/prompt-injection-use-cases/"],"supporting-entities":["OWASP","Microsoft","LangChain"]}
{"id":"ai-summaries-replacing-understanding-2023","title":"AI Summaries Replacing Understanding","year":2023,"evidence-type":"repeated-pattern","category":"ai-slop","cause":"ai","stage":"scale","impact":["morale"],"severity":{"level":"medium","score":5,"financial":"Indirect"},"summary":"Teams relied on AI-generated summaries instead of reading source data, leading to cascading bad strategic decisions based on incomplete understanding.","root-cause":"Delegating thinking not just toil, AI used to compress data but output treated as authoritative","lessons":["AI should compress data, not replace judgment","Leaders must still read the source for critical decisions","Summary is a starting point, not the endpoint of reasoning"],"patterns":["decision-making-by-proxy","blind-trust-in-ai-output"],"tags":["ai-summaries","decision-degradation","blind-trust","automation-bias"],"sources":["https://www.mckinsey.com/capabilities/strategy-and-corporate-finance/our-insights/the-risk-of-relying-on-ai-summaries","https://hbr.org/2023/09/how-ai-is-changing-decision-making","https://news.ycombinator.com/item?id=39102457"],"supporting-entities":["McKinsey","Harvard Business Review","Various Organizations"]}
{"id":"vibe-coding-unmaintainable-2024","title":"Vibe Coding Unmaintainable Systems","year":2024,"evidence-type":"repeated-pattern","category":"ai-slop","cause":"ai","stage":"early","impact":["morale"],"severity":{"level":"low","score":4,"financial":"Technical debt"},"summary":"Teams used AI coding tools extensively to build entire features or backends, only to discover the code was unmaintainable, undocumented, and impossible for humans to extend.","root-cause":"Vibe coding — generating code without understanding it, no documentation generated, no architectural oversight","lessons":["Code you don't understand is technical debt from day one","AI can generate code, but humans must own architecture","Require documentation and code review for AI-generated code"],"patterns":["blind-trust-in-ai-output","overconfidence-from-past-success"],"tags":["vibe-coding","technical-debt","ai-generated-codebase","unmaintainable"],"sources":["https://news.ycombinator.com/item?id=39852103","https://www.getrevue.co/profileengineering/p/vibe-coding-retrospective","https://www.indiehackers.com/post/what-happened-when-we-let-ai-write-our-whole-backend"],"supporting-entities":["Indie Hackers","Engineering Blogs","Various Teams"]}
{"id":"over-automated-customer-support-2023","title":"Over-Automated Customer Support Destroying Trust","year":2023,"evidence-type":"direct-incident","category":"ai-slop","cause":"automation","stage":"scale","impact":["trust"],"severity":{"level":"medium","score":6,"financial":"Customer churn"},"summary":"Companies deployed AI customer support chatbots without adequate human escalation paths, leading to misinformation, frustrated customers, and trust damage.","root-cause":"Cost-cutting focus over customer experience, no clear escalation paths, chatbots empowered to make promises they couldn't keep","lessons":["Customer trust is hard to earn, easy to lose","AI chatbots need clear escalation paths to humans","Never let AI make promises it can't verify"],"patterns":["automation-without-reversal","decision-making-by-proxy"],"tags":["customer-support","chatbot-failure","no-escalation","trust-destruction"],"sources":["https://www.cbc.ca/news/canada/air-canada-ai-chatbot-misinformation-1.7139752","https://news.ycombinator.com/item?id=40231568","https://www.gsb.stanford.edu/insights/when-automation-goes-wrong-customer-service"],"supporting-entities":["Air Canada","Stanford GSB","Various Companies"]}
{"id":"github-database-outage-2018","title":"GitHub Database Outage","year":2018,"evidence-type":"direct-incident","category":"outage","cause":"architecture","stage":"scale","impact":["users"],"severity":{"level":"high","score":8,"financial":"Productivity loss"},"summary":"A routine maintenance operation triggered a large-scale MySQL replication failure, causing hours of downtime across GitHub's platform.","root-cause":"Overconfidence in replication infrastructure, insufficient understanding of failure modes, restore paths never tested","lessons":["Backups are useless if restore paths are not tested","We have done this before is not a safety guarantee","Understand failure modes before they happen"],"patterns":["hidden-single-point-of-failure","overconfidence-from-past-success"],"tags":["hidden-dependency","rollback-failure","observability-gap","mysql","replication"],"sources":["https://github.blog/2018-10-30-october-incident-report/"],"supporting-entities":["GitHub"]}
{"id":"aws-s3-us-east-1-2017","title":"AWS S3 us-east-1 Outage","year":2017,"evidence-type":"direct-incident","category":"outage","cause":"human-error","stage":"scale","impact":["users"],"severity":{"level":"critical","score":10,"financial":"$100M+"},"summary":"A typo during debugging commands took down S3 in the us-east-1 region, cascading into major internet outages for thousands of services.","root-cause":"Human error during debugging, insufficient blast-radius controls, region-level dependencies as silent killers","lessons":["Highly available does not mean invulnerable","Region-level dependencies are silent killers","Debugging in production requires extreme caution"],"patterns":["hidden-single-point-of-failure","automation-without-reversal"],"tags":["blast-radius","control-plane","region-dependency","s3","typo"],"sources":["https://aws.amazon.com/message/41926/"],"supporting-entities":["AWS"]}
{"id":"knight-capital-2012","title":"Knight Capital Trading Loss","year":2012,"evidence-type":"direct-incident","category":"outage","cause":"automation","stage":"scale","impact":["money"],"severity":{"level":"critical","score":10,"financial":"$440M"},"summary":"A faulty deployment activated dead code paths in Knight Capital's trading system, triggering uncontrolled trading that lost approximately $440M in under an hour.","root-cause":"Broken deployment process, dead code left in production, no kill switches, automation without human oversight","lessons":["Automation without kill switches is lethal","Old code is still production code — audit and remove dead paths","Every automated system needs a tested emergency stop"],"patterns":["automation-without-reversal"],"tags":["no-rollback","deployment-failure","trading-automation","dead-code","kill-switch"],"sources":["https://www.sec.gov/spotlight/equity-markets-structure-committee/knight-capital-report.pdf"],"supporting-entities":["Knight Capital","SEC"]}
{"id":"cloudflare-regex-catastrophe-2019","title":"Cloudflare Regex Catastrophe","year":2019,"evidence-type":"direct-incident","category":"outage","cause":"architecture","stage":"scale","impact":["trust"],"severity":{"level":"high","score":8,"financial":"Global disruption"},"summary":"A single regex rule deployed to Cloudflare's WAF caused CPU exhaustion across all HTTP/HTTPS servers worldwide, resulting in 30+ minutes of 502 errors.","root-cause":"The regex caused catastrophic backtracking, rule not tested for CPU impact, safety mechanism removed by mistake","lessons":["Test regex performance before deployment","Any change to safety mechanisms requires review and rollback plan","Single points of failure in safety systems are catastrophic"],"patterns":["overconfidence-from-past-success"],"tags":["regex","backtracking","cpu-exhaustion","waf","global-impact","cascade"],"sources":["https://blog.cloudflare.com/details-of-the-cloudflare-outage-on-july-2-2019/"],"supporting-entities":["Cloudflare"]}
{"id":"capital-one-breach-2019","title":"Capital One Breach","year":2019,"evidence-type":"direct-incident","category":"security","cause":"human-error","stage":"scale","impact":["trust"],"severity":{"level":"high","score":9,"financial":"$80M fine"},"summary":"An attacker exploited a misconfigured cloud firewall combined with SSRF to access sensitive customer data stored in AWS, exposing 100M records.","root-cause":"Misconfigured IAM roles with over-privileged access, internal services assumed trusted without validation","lessons":["Cloud security failures are often configuration, not complex exploits","Assume internal services will be abused — apply zero-trust principles","IAM permissions should follow least-privilege"],"patterns":["misconfigured-trust-boundaries"],"tags":["misconfiguration","iam","ssrf","cloud-security","over-privileged-access"],"sources":["https://www.justice.gov/opa/press-release/file/1244101/download"],"supporting-entities":["Capital One","DOJ"]}
{"id":"equifax-breach-2017","title":"Equifax Breach","year":2017,"evidence-type":"direct-incident","category":"security","cause":"human-error","stage":"scale","impact":["data-loss"],"severity":{"level":"critical","score":10,"financial":"$1.38B"},"summary":"Attackers exploited a known Apache Struts vulnerability that had a patch available for 2 months, exposing 147.9 million Americans' data.","root-cause":"Failure to patch a critical vulnerability despite knowing about it, no network segmentation, plaintext credentials","lessons":["Patch critical vulnerabilities within hours/days, not weeks/months","Network segmentation limits blast radius of initial compromise","Store credentials securely"],"patterns":["patching-debt"],"tags":["unpatched","apache-struts","credential-lateral-movement","no-segmentation","regulatory-fine"],"sources":["https://www.breachsense.com/blog/equifax-data-breach/"],"supporting-entities":["Equifax","BreachSense"]}
{"id":"multi-agent-loop-2025","title":"Autonomous Multi-Agent Loop Cost Spike","year":2025,"evidence-type":"direct-incident","category":"ai-slop","cause":"automation","stage":"scale","impact":["money"],"severity":{"level":"medium","score":6,"financial":"$47k+"},"summary":"A multi-agent research system with four LangChain agents deployed recursive A2A delegation through MCP, entering a clarification loop that burned $47,000.","root-cause":"No recursive depth limits on agent-to-agent delegation; no global budget controller; MCP protocols standardize connectivity but lack governance.","lessons":["Multi-agent systems require a central orchestrator with explicit recursion depth limits (max 3-5 hops)","Implement token-bucket rate limiting at the organization level, not per-agent","Recursive delegation must require explicit human approval after 3 hops","Monitor inter-agent communication patterns for circular reasoning and clarification loops","Deploy real-time cost monitoring with hard kill-switches per workflow"],"patterns":["automation-without-reversal","hidden-single-point-of-failure","recursive-dependency-cascade"],"tags":["multi-agent","mcp","cost-explosion","recursive-delegation","runaway-agents","A2A"],"sources":["https://arxiv.org/html/2601.08815v1","https://youssefh.substack.com/p/we-spent-47000-running-ai-agents","https://arxiv.org/html/2512.08290v1"],"supporting-entities":["Engineering team (Ye & Tan study)","Teja Kusireddy"]}
{"id":"agentic-db-migration-2025","title":"Agentic Database Migration Data Corruption","year":2025,"evidence-type":"repeated-pattern","category":"ai-slop","cause":"ai","stage":"growth","impact":["data-loss"],"severity":{"level":"high","score":8,"financial":"High recovery cost"},"summary":"Multiple incidents where AI agents performing autonomous database operations misidentified resources due to schema hallucinations, executing destructive commands.","root-cause":"Agents given write access without dry-run validation; documentation fed to RAG agents outdated/inconsistent; no mandatory human-in-loop verification.","lessons":["Database migrations are always high-stakes operations requiring human-in-loop verification","Agentic AI must run schema-checking tools (pg_dump, SQLFluff) BEFORE suggesting changes","Documentation fed to RAG systems must be versioned and synchronized with live schema","Autonomous operations require Shadow Mode evaluation before write access","Implement mandatory approval gates for any destructive operations"],"patterns":["blind-trust-in-ai-output","automation-without-reversal","schema-hallucination-in-rag-systems","hidden-single-point-of-failure"],"tags":["agentic-migration","data-corruption","schema-hallucination","autonomous-ops","blind-trust-in-ai"],"sources":["https://www.matechco.com/blog/agentic-ai-hidden-risks","https://www.youtube.com/watch?v=QXQfw3fiR8k","https://muhammadraza.me/2025/building-ai-agents-devops-automation/","https://www.kellton.com/kellton-tech-blog/revealing-top-data-migration-trends","https://kanerika.com/blogs/data-governance-challenges-in-agentic-ai-systems/"],"supporting-entities":["Fortune 500 company (anonymized)","Clumio/Commvault","AI agents deployed across various enterprises"]}
{"id":"gitlab-data-loss-2017","title":"GitLab Sysadmin Database Deletion","year":2017,"evidence-type":"direct-incident","category":"outage","cause":"human-error","stage":"scale","impact":["data-loss"],"severity":{"level":"high","score":8,"financial":"Unknown"},"summary":"A system administrator accidentally deleted 300GB of live production data by running rm -rf on the wrong directory during maintenance.","root-cause":"Human error due to fatigue and lack of guardrails, multiple levels of backups failed or were empty","lessons":["Backups are only as good as your last successful restore test","Implement guardrails for destructive commands","Engineer systems to be resilient to human error at 2 AM"],"patterns":["automation-without-reversal","overconfidence-from-past-success"],"tags":["data-loss","backup-failure","human-error","postgresql","replication"],"sources":["https://about.gitlab.com/blog/2017/02/10/postmortem-of-database-outage-of-january-31/"],"supporting-entities":["GitLab"]}
{"id":"fastly-outage-2021","title":"Fastly Global Config Outage","year":2021,"evidence-type":"direct-incident","category":"outage","cause":"architecture","stage":"scale","impact":["users"],"severity":{"level":"high","score":9,"financial":"Significant"},"summary":"A single valid configuration change by one customer triggered a dormant software bug in Fastly's edge cloud, taking down major sites globally.","root-cause":"Dormant bug in the VCL compiler triggered by specific parameters, failure to isolate service-wide impacts","lessons":["Individual customer actions should never trigger global failures","Implement cell-based architecture to limit blast radius","Fast rollbacks are the best defense against unknown triggers"],"patterns":["hidden-single-point-of-failure","automation-without-reversal"],"tags":["vcl","global-outage","cascading-failure","edge-computing","hidden-sop"],"sources":["https://www.fastly.com/blog/summary-of-june-8-incident"],"supporting-entities":["Fastly"]}
{"id":"solarwinds-supply-chain-2020","title":"SolarWinds Orion Supply Chain Attack","year":2020,"evidence-type":"direct-incident","category":"security","cause":"architecture","stage":"scale","impact":["trust"],"severity":{"level":"critical","score":10,"financial":"Massive"},"summary":"APT29 compromised the software build process to inject the SUNBURST backdoor into signed Orion updates distributed to 30,000+ organizations.","root-cause":"Attackers compromised the automated build process—a less obvious attack surface than source control; exfiltration masked as legitimate traffic.","lessons":["Build infrastructure is as critical as source control","Supply chain attacks succeed by exploiting trust in software updates","Cryptographic signing does not ensure integrity if the signing key is compromised"],"patterns":["hidden-single-point-of-failure","misconfigured-trust-boundaries"],"tags":["supply-chain","build-infrastructure-compromise","nation-state-access","solarwinds","2020-major"],"sources":["https://cloud.google.com/blog/topics/threat-intelligence/sunburst-backdoor-analysis"],"supporting-entities":["SolarWinds","Google Cloud","APT29"]}
{"id":"uber-breach-2022","title":"Uber Social Engineering Breach","year":2022,"evidence-type":"direct-incident","category":"security","cause":"human-error","stage":"scale","impact":["trust"],"severity":{"level":"high","score":9,"financial":"Significant"},"summary":"An attacker gained access to internal Uber systems by bombarding an employee with MFA push notifications and then posing as IT support.","root-cause":"Reliance on push-based MFA vulnerable to fatigue, lack of internal zero-trust, human vulnerability","lessons":["Shift from push-based MFA to security keys to prevent fatigue","Apply zero-trust internally: password should not grant full access","Train employees on social engineering tactics"],"patterns":["misconfigured-trust-boundaries","overconfidence-from-past-success"],"tags":["social-engineering","mfa-fatigue","privileged-access","human-factor","data-exposure"],"sources":["https://www.uber.com/newsroom/security-update/"],"supporting-entities":["Uber"]}
{"id":"multi-agent-failures-arxiv-2025","title":"Multi-Agent LLM System Failures","year":2025,"evidence-type":"repeated-pattern","category":"ai-slop","cause":"architecture","stage":"scale","impact":["users"],"severity":{"level":"high","score":8,"financial":"Indirect"},"summary":"Analysis of 1,600+ traces shows coordination failures in 41% to 86.7% of multi-agent implementations.","root-cause":"Lack of organizational structure—clear role definitions, communication protocols, and verification mechanisms.","lessons":["Coordination failures dominate; intelligence is not the limiting factor","Systems require explicit approval chains and verification layers","Unclear goals and role ambiguity cascade"],"patterns":["decision-making-by-proxy","hidden-single-point-of-failure"],"tags":["coordination-failure","system-design","multi-agent-llm","verification-gap"],"sources":["https://arxiv.org/abs/2410.12352"],"supporting-entities":["ArXiv","MAST-Data Research Team"]}
{"id":"rag-hallucination-cascades-2025","title":"RAG Hallucination Cascades","year":2025,"evidence-type":"repeated-pattern","category":"ai-slop","cause":"ai","stage":"scale","impact":["trust"],"severity":{"level":"high","score":8,"financial":"Brand Damage"},"summary":"Hallucination detection tools failed on 83% of production examples, allowing false context to amplify factual errors.","root-cause":"RAG systems inherit model hallucinations; poor retrieval quality allows false context to amplify errors.","lessons":["RAG reduces hallucinations but does not eliminate them; verification is essential","Retrieval quality directly impacts downstream accuracy","Continuous testing against real failure patterns"],"patterns":["blind-trust-in-ai-output","overconfidence-from-past-success"],"tags":["hallucination","rag-degradation","business-logic-bypass","detection-failure"],"sources":["https://www.linkedin.com/pulse/why-rag-projects-fail-2025-adrian-faryniuk/"],"supporting-entities":["LinkedIn","Various Organizations"]}
{"id":"ai-coding-rules-backdoor-2025","title":"AI Coding Assistant Rules File Backdoor","year":2025,"evidence-type":"direct-incident","category":"ai-slop","cause":"architecture","stage":"scale","impact":["data-loss"],"severity":{"level":"critical","score":9,"financial":"Massive Potential"},"summary":"Attackers can inject malicious instructions via hidden Unicode in project config files to manipulate AI into generating backdoors.","root-cause":"AI assistants lack trust boundaries between user-controlled config files and system instructions.","lessons":["Treat configuration files with the same security rigor as code","Invisible characters and Unicode obfuscation can evade standard review","Trust in AI tools compounds supply chain risk"],"patterns":["misconfigured-trust-boundaries","hidden-single-point-of-failure"],"tags":["supply-chain","config-injection","backdoor-insertion","ai-assistant"],"sources":["https://www.pillar.security/blog/rules-file-backdoor"],"supporting-entities":["Pillar Security","GitHub","Cursor"]}
{"id":"model-collapse-nature-2024","title":"Synthetic Data Poisoning & Model Collapse","year":2024,"evidence-type":"repeated-pattern","category":"ai-slop","cause":"ai","stage":"scale","impact":["users"],"severity":{"level":"high","score":7,"financial":"Retraining Costs"},"summary":"Recursive training on synthetic data without human anchoring causes progressive degradation and loss of rare patterns.","root-cause":"Statistical and functional approximation errors compound exponentially when no human ground truth anchors the distribution.","lessons":["Mixing human and synthetic data prevents collapse","Early collapse is hard to detect; performance may mask tail degradation","Multi-modal systems exhibit unique collapse patterns"],"patterns":["blind-trust-in-ai-output","decision-making-by-proxy"],"tags":["data-degradation","synthetic-recursion","performance-loss","model-collapse"],"sources":["https://www.nature.com/articles/s41586-024-07566-y"],"supporting-entities":["Nature","Academic Researchers"]}
{"id":"agentic-cost-explosions-2025","title":"Agentic Workflow Cost Explosions","year":2025,"evidence-type":"repeated-pattern","category":"ai-slop","cause":"automation","stage":"scale","impact":["money"],"severity":{"level":"medium","score":6,"financial":"10x budget"},"summary":"AI agent deployments experienced 10x cost spirals due to token bloat, function-calling recursion, and lack of circuit breakers.","root-cause":"Development environments don't reflect production complexity; token usage multiplies across agent handoffs.","lessons":["Test with production-scale data volumes and real API limits","Multi-agent systems require aggressive token caching","Set hard budget limits with automatic circuit breakers"],"patterns":["automation-without-reversal","blind-trust-in-ai-output"],"tags":["cost-runaway","token-bloat","budget-explosion","agentic-workflow"],"sources":["https://www.linkedin.com/pulse/your-ai-agent-just-burned-10x-weekly-budget-nav-bhasin/"],"supporting-entities":["LinkedIn","Datgrid","Various Organizations"]}
{"id":"cloudflare-bot-mgmt-2025","title":"Cloudflare Bot Management Feature File Corruption","year":2025,"evidence-type":"direct-incident","category":"outage","cause":"automation","stage":"scale","impact":["users"],"severity":{"level":"high","score":9,"financial":"Significant"},"summary":"A database permission change caused the Bot Management feature file to double in size, exceeding routing software limits globally.","root-cause":"Oversized file not caught by upstream validation; software had hard limit that wasn't enforced until network propagation.","lessons":["Configuration changes can have exponential effects; test at scale","Enforce size limits at source, not just at consumption","Distinguish DDoS from internal cascade early"],"patterns":["hidden-single-point-of-failure","automation-without-reversal"],"tags":["cascading-failure","config-propagation","global-outage","feature-file-poisoning","2025-active"],"sources":["https://blog.cloudflare.com/outage-report-november-18-2025/"],"supporting-entities":["Cloudflare"]}
{"id":"meta-cascading-failure-2024","title":"Meta Cascading Service Failure","year":2024,"evidence-type":"direct-incident","category":"outage","cause":"architecture","stage":"scale","impact":["users"],"severity":{"level":"high","score":8,"financial":"Significant"},"summary":"Technical issues in Meta's infrastructure cascaded across Facebook, Instagram, Threads, and WhatsApp due to shared backend dependencies.","root-cause":"Infrastructure-level issue cascaded due to tight coupling and shared backend dependencies among multiple platforms.","lessons":["Shared infrastructure creates cascading risk","Complex interdependencies are invisible until they fail","Long MTTR indicates detection/coordination gaps"],"patterns":["hidden-single-point-of-failure","overconfidence-from-past-success"],"tags":["cascading-failure","shared-dependency","global-outage","social-media","2024-major"],"sources":["https://www.cnbc.com/2024/12/11/metas-facebook-instagram-go-down.html"],"supporting-entities":["Meta","CNBC"]}
{"id":"aws-observability-failure-2025","title":"AWS Observability Stack Co-Located Failure","year":2025,"evidence-type":"direct-incident","category":"outage","cause":"architecture","stage":"scale","impact":["users"],"severity":{"level":"high","score":8,"financial":"Indirect"},"summary":"Outage in us-east-1 took down production workloads and the observability stack co-located in the same region, leaving engineers blind.","root-cause":"Architectural decision to co-locate monitoring with production; lack of geographic redundancy for observability systems.","lessons":["Observability must be external to monitored systems","Regional failures require cross-region monitoring","AI cannot help if you are blind during the incident"],"patterns":["hidden-single-point-of-failure","decision-making-by-proxy"],"tags":["observability-gap","architecture","visibility-loss","regional-outage","2025-critical"],"sources":["https://www.linkedin.com/pulse/when-observability-fails-what-we-can-learn-from-aws-outage/"],"supporting-entities":["AWS","LinkedIn"]}
{"id":"crowdstrike-falcon-outage-2024","title":"CrowdStrike Falcon Sensor Faulty Update","year":2024,"evidence-type":"direct-incident","category":"outage","cause":"automation","stage":"scale","impact":["money"],"severity":{"level":"critical","score":10,"financial":"$5B+"},"summary":"Faulty sensor update triggered crashes on 8.5M Windows devices globally; largest IT outage in history requiring manual remediation.","root-cause":"Insufficient pre-deployment testing and lack of staged rollout; update deployed globally without canary validation.","lessons":["Endpoint updates require most rigorous testing","Canary deployments are non-negotiable","Rollbacks requiring physical access are disasters"],"patterns":["automation-without-reversal","overconfidence-from-past-success"],"tags":["rollback-failure","deployment-validation","systemic-outage","endpoint-security","2024-worst"],"sources":["https://www.crowdstrike.com/blog/falcon-content-update-remediation-and-guidance-hub/"],"supporting-entities":["CrowdStrike"]}
{"id":"cloudflare-ddos-rule-failure-2024","title":"Cloudflare DDoS Rule Deployment Failure","year":2024,"evidence-type":"direct-incident","category":"outage","cause":"architecture","stage":"scale","impact":["users"],"severity":{"level":"medium","score":7,"financial":"Significant"},"summary":"New DDoS rule triggered a latent bug in rate-limiting system, causing CPU spikes and global error rates of 1-3%.","root-cause":"Broken cookie validation in new rule triggered exception; latent interaction not exercised in staging.","lessons":["Latent bugs can be triggered by new code paths","Gradual rollout must include failure detection","Distinguish internal cascades from external attacks"],"patterns":["hidden-single-point-of-failure","overconfidence-from-past-success"],"tags":["rollback-failure","latent-bug","error-spike","ddos-rule","2024-major"],"sources":["https://blog.cloudflare.com/incident-report-june-20-2024/"],"supporting-entities":["Cloudflare"]}
{"id":"twitch-leak-2021","title":"Twitch Source Code Leak","year":2021,"evidence-type":"direct-incident","category":"security","cause":"human-error","stage":"scale","impact":["trust"],"severity":{"level":"high","score":9,"financial":"Significant"},"summary":"A server configuration change exposed 125GB of data, including Twitch's complete source code and internal tools.","root-cause":"Server configuration error during a system change made an S3 bucket or similar storage service publicly accessible.","lessons":["Configuration changes are leading cause of data exposure","Secrets in source code are a systemic vulnerability","Once code is leaked, assume all embedded secrets are compromised"],"patterns":["misconfigured-trust-boundaries"],"tags":["cloud-misconfiguration","s3-public-access","source-code-leak","secrets-exposure","2021-major"],"sources":["https://www.bbc.com/news/technology-58817658"],"supporting-entities":["Twitch","BBC"]}
{"id":"github-codeql-vulnerability-2025","title":"GitHub CodeQL Supply Chain Vulnerability","year":2025,"evidence-type":"direct-incident","category":"security","cause":"architecture","stage":"scale","impact":["trust"],"severity":{"level":"critical","score":9,"financial":"Massive Potential"},"summary":"Brief token exposure in CodeQL artifacts allowed modification of immutable tags, risking exfiltration from hundreds of thousands of repos.","root-cause":"Non-immutable tags in official actions and token exposure in workflow artifacts.","lessons":["CI/CD supply chain attacks are effective and dangerous","Immutable tags and workflow pinning are not optional","Cache poisoning is a persistent threat"],"patterns":["misconfigured-trust-boundaries","hidden-single-point-of-failure"],"tags":["supply-chain","token-exposure","code-exfiltration","github-actions","2025-active"],"sources":["https://www.praetorian.com/blog/codeqleaked-public-secrets-exposure/"],"supporting-entities":["GitHub","Praetorian"]}
{"id":"log4shell-2021","title":"Log4Shell — Global RCE","year":2021,"evidence-type":"direct-incident","category":"security","cause":"architecture","stage":"scale","impact":["trust"],"severity":{"level":"critical","score":10,"financial":"Massive"},"summary":"A remote code execution vulnerability in Log4j 2 allowed attackers to run arbitrary code via malicious JNDI lookups in crafted log messages.","root-cause":"Log4j message lookup feature did not validate or sandbox JNDI references; existed unnoticed since 2013.","lessons":["Dynamic code execution features are inherently dangerous","User input flowing to logs is a critical attack surface","Widespread usage increases blast radius significantly"],"patterns":["hidden-single-point-of-failure"],"tags":["zero-day","unsafe-feature","rce-global","log4j","2021-critical"],"sources":["https://logging.apache.org/log4j/2.x/security.html"],"supporting-entities":["Apache","OWASP"]}
{"id":"booking-oauth-redirect-2023","title":"Booking.com OAuth Redirect URI Misconfiguration","year":2023,"evidence-type":"direct-incident","category":"security","cause":"human-error","stage":"scale","impact":["trust"],"severity":{"level":"high","score":8,"financial":"Significant"},"summary":"Loose path matching on redirect URIs allowed authorization code theft and account takeovers.","root-cause":"Application-layer implementation did not enforce exact path matching for redirect URIs.","lessons":["OAuth client applications must validate strictly","Exact path matching is required, not just domain validation","Open redirects are dangerous vectors in auth flows"],"patterns":["misconfigured-trust-boundaries"],"tags":["authentication-bypass","oauth-misconfiguration","account-takeover","redirect-uri","2023-pattern"],"sources":["https://www.descope.com/blog/post/oauth-vulnerabilities"],"supporting-entities":["Booking.com","Descope"]}
{"id":"expo-oauth-token-leak-2023","title":"Expo OAuth Token Exposure","year":2023,"evidence-type":"direct-incident","category":"security","cause":"architecture","stage":"scale","impact":["trust"],"severity":{"level":"high","score":8,"financial":"Significant"},"summary":"Manipulation of the returnURL parameter allowed OAuth tokens to be sent to attacker-controlled domains.","root-cause":"Insufficient validation of the returnURL parameter in OAuth proxy.","lessons":["Return URL validation must be as strict as redirect URI validation","OAuth proxies introduce additional validation requirements"],"patterns":["misconfigured-trust-boundaries"],"tags":["authentication-bypass","oauth-parameter-injection","account-takeover","token-leakage","2023-pattern"],"sources":["https://www.descope.com/blog/post/oauth-vulnerabilities"],"supporting-entities":["Expo","Descope"]}
{"id":"unit42-social-eng-trend-2025","title":"Unit 42 Social Engineering Trend Report","year":2025,"evidence-type":"repeated-pattern","category":"security","cause":"human-error","stage":"scale","impact":["trust"],"severity":{"level":"high","score":8,"financial":"Global Trend"},"summary":"Social engineering accounted for 36% of all incidents, with a shift towards SEO poisoning and help desk manipulation.","root-cause":"Attackers exploit human behavior; weak access controls amplify damage after initial compromise.","lessons":["Social engineering succeeds through behavior, not sophistication","Weak controls amplify impact","Detection gaps mask critical signals"],"patterns":["misconfigured-trust-boundaries","decision-making-by-proxy"],"tags":["human-factor","trust-exploitation","data-exfiltration","bec","2025-trend"],"sources":["https://unit42.paloaltonetworks.com/global-incident-response-report/"],"supporting-entities":["Unit 42","Palo Alto Networks"]}
{"id":"lexisnexis-github-breach-2024","title":"LexisNexis GitHub Account Compromise","year":2024,"evidence-type":"direct-incident","category":"security","cause":"human-error","stage":"scale","impact":["trust"],"severity":{"level":"high","score":9,"financial":"Significant"},"summary":"Attacker gained access via pretexting and exfiltrated personal data for 364,000+ individuals from development platforms.","root-cause":"Weak authentication on GitHub and human vulnerability to pretexting.","lessons":["GitHub access is equivalent to internal infrastructure access","Social engineering targets help desk/support staff","Third-party dev platforms hold sensitive data"],"patterns":["misconfigured-trust-boundaries","overconfidence-from-past-success"],"tags":["social-engineering","credential-compromise","pii-exfiltration","github-access","2024-major"],"sources":["https://techcrunch.com/2025/05/27/data-broker-lexisnexis-breach-exposed-364k-people/"],"supporting-entities":["LexisNexis","TechCrunch"]}
{"id":"quibi-2020","title":"Quibi — $1.75B Burn in 6 Months","year":2020,"evidence-type":"direct-incident","category":"startup","cause":"incentives","stage":"growth","impact":["money"],"severity":{"level":"high","score":9,"financial":"$1.75B"},"summary":"Quibi burned $1.75B in 6 months trying to create Netflix for your phone, failing due to fundamentally wrong market assumptions.","root-cause":"No product-market fit; wrong assumptions about mobile viewing; production quality didn't solve distribution problem.","lessons":["Money doesn't buy demand","TIMING assumptions must be tested","Content differentiation must be obvious"],"patterns":["overconfidence-from-past-success","decision-making-by-proxy"],"tags":["no-pmf","timing","distribution","wrong-assumptions","premium-content"],"sources":["https://www.theinformation.com/articles/quibi-the-rise-and-fall-of-a-1-75-billion-failure"],"supporting-entities":["Quibi","The Information"]}
{"id":"google-glass-2014","title":"Google Glass — Technology Ahead of Society","year":2014,"evidence-type":"direct-incident","category":"product","cause":"timing","stage":"growth","impact":["trust"],"severity":{"level":"medium","score":6,"financial":"Reputational"},"summary":"Google launched a $1,500 smart glass device that failed due to privacy backlash and lack of social acceptance.","root-cause":"Technology was 5-10 years ahead of social acceptance; privacy concerns (Glassholes); no killer app.","lessons":["Technology readiness ≠ market readiness","Social acceptance is a critical product requirement","Privacy concerns are product risks"],"patterns":["timing-blindness"],"tags":["premature","privacy","fashion","user-acceptance","enterprise-pivot"],"sources":["https://www.investopedia.com/articles/investing/052115/how-why-google-glass-failed.asp"],"supporting-entities":["Google"]}
{"id":"google-wave-2012","title":"Google Wave — Technically Impressive, User Failure","year":2012,"evidence-type":"direct-incident","category":"product","cause":"incentives","stage":"growth","impact":["users"],"severity":{"level":"medium","score":5,"financial":"Project cost"},"summary":"A revolutionary collaboration tool that failed because users couldn't understand its value proposition without tutorials.","root-cause":"UX complexity too high; unclear value proposition; marketing confused novelty with user value.","lessons":["Cool tech doesn't create demand","If users need tutorials, you're in trouble","Value proposition must be obvious"],"patterns":["ecosystem-neglect"],"tags":["ux-mismatch","wrong-market","documentation-heavy","collaboration-complexity"],"sources":["https://googleblog.blogspot.com/2012/08/update-on-google-wave.html"],"supporting-entities":["Google"]}
{"id":"windows-phone-2017","title":"Windows Phone — Ecosystem Neglect","year":2017,"evidence-type":"direct-incident","category":"product","cause":"incentives","stage":"scale","impact":["users"],"severity":{"level":"critical","score":9,"financial":"Billions"},"summary":"Microsoft's mobile OS failed despite good design because it launched late and ignored the app gap.","root-cause":"Late market entry; developer ecosystem neglected; app gap persisted too long due to lack of developer trust.","lessons":["Platforms live or die by ecosystems","Developer trust is non-renewable","Late entry requires 10x better, not 10% better"],"patterns":["ecosystem-neglect"],"tags":["ecosystem-failure","platform-risk","late-entry","app-gap"],"sources":["https://www.theverge.com/2017/10/8/16437700/microsoft-windows-phone-dead"],"supporting-entities":["Microsoft"]}
{"id":"kodak-bankruptcy-2012","title":"Kodak — Invented Digital, Buried It","year":2012,"evidence-type":"direct-incident","category":"decision","cause":"incentives","stage":"scale","impact":["money"],"severity":{"level":"critical","score":10,"financial":"Bankruptcy"},"summary":"Kodak invented the digital camera in 1975 but buried it for 20 years to protect film profits, leading to bankruptcy.","root-cause":"Innovator's Dilemma; leadership incentives tied to short-term film profits; fear of cannibalization.","lessons":["Incentives that reward defending the past destroy the future","Cannibalization fear delays the inevitable","Innovation requires separate metrics"],"patterns":["innovators-dilemma"],"tags":["innovators-dilemma","fear-of-cannibalization","short-term-incentives","missed-opportunity"],"sources":["https://quartr.com/insights/edge/the-dilemma-that-brought-down-kodak"],"supporting-entities":["Kodak"]}
{"id":"hypersense-ai-agents-fail-2025","title":"HyperSense — 88% of AI Agents Fail to Reach Production","year":2025,"evidence-type":"repeated-pattern","category":"ai-slop","cause":"automation","stage":"scale","impact":["money","morale","trust"],"severity":{"level":"high","score":8,"financial":"Industry-wide"},"summary":"Industry analysis found 88% of AI agent projects fail to reach production or fail shortly after deployment. Only 12% achieve sustainable production use.","root-cause":"Expectations mismatch (35%), insufficient guardrails (25%), hallucination issues (20%), integration complexity (15%), insufficient testing (5%).","lessons":["Implement shadow mode evaluation before granting write access to agents","Test agents on adversarial inputs before production deployment","Start agents small without high-stakes access"],"patterns":["blind-trust-in-ai-output","automation-without-reversal","over-hyped-technology"],"tags":["agentic-ai","production-failure","macro-trend","systemic-failure","deployment-challenges"],"sources":["https://hypersensesoftware.com/blog/88-percent-ai-agents-fail-production","https://www.techcrunch.com/2025/11/ai-agents-fail-rate","https://www.gartner.com/en/articles/ai-agent-failure-rates-2026"],"supporting-entities":["HyperSense Software","Gartner","Multiple AI Vendors"]}
{"id":"galileo-ai-agentic-failures-2025","title":"Galileo AI — 40% of Agentic AI Projects Fail","year":2025,"evidence-type":"repeated-pattern","category":"ai-slop","cause":"automation","stage":"scale","impact":["money","trust"],"severity":{"level":"high","score":8,"financial":"10-100x budget overruns"},"summary":"Galileo AI research on Hidden Costs of Agentic AI found that 40% of agentic AI projects fail primarily due to cost explosion and guardrail issues.","root-cause":"Cost explosion (no rate limiting, API calls exceed budget), insufficient guardrails (runaway agents take unintended actions), context/hallucination (agents lose context between steps), integration failures (lack of circuit breakers).","lessons":["Rate limiting and cost monitoring are mandatory for any agentic deployment","Test long-running workflows specifically for context management and drift","Implement approval gates for any action with cost or side-effect implications","Build circuit breakers at the integration layer to prevent cascading failures"],"patterns":["automation-without-reversal","blind-trust-in-ai-output","overconfidence-from-past-success"],"tags":["agentic-ai","cost-explosion","guardrails","context-loss","integration-failure"],"sources":["https://dsn2024uq.github.io/Proceedings/pdfs/DSN2024-6rvE3SSpzFYmysif75Dkid/410500a001/410500a001.pdf","https://kubernetes.io/blog/2025/10/20/seven-kubernetes-pitfalls-and-how-to-avoid/"],"supporting-entities":["Galileo AI","DSN 2024","Kubernetes Blog"]}
{"id":"futureagi-rag-failure-modes-2025","title":"FutureAGI / Dev.to — RAG System Hallucination Failures (10+ Modes)","year":2025,"evidence-type":"repeated-pattern","category":"ai-slop","cause":"ai","stage":"scale","impact":["trust"],"severity":{"level":"high","score":8,"financial":"Variable"},"summary":"Academic analysis documented 10+ distinct failure modes in RAG systems deployed in production.","root-cause":"RAG systems inherit LLM hallucination tendencies while adding new failure modes specific to retrieval.","lessons":["Document quality is existential for RAG systems","Monitor retrieval quality separately from answer quality","Implement strict refusal logic for low-confidence results"],"patterns":["blind-trust-in-ai-output","hallucination-in-production","system-brittleness"],"tags":["rag","hallucination","retrieval-failure","document-quality","semantic-search"],"sources":["https://dev.to/kuldeep_paul/ten-failure-modes-of-rag-nobody-talks-about-and-how-to-detect-them-systematically-7i4","https://futureagi.com/blogs/rag-hallucinations-future-agi-2025"],"supporting-entities":["FutureAGI","Dev.to Community","Academic Researchers"]}
{"id":"kubernetes-cluster-failures-2024","title":"Kubernetes — Cluster-Wide Failures (51% Dependency-Related)","year":2024,"evidence-type":"repeated-pattern","category":"outage","cause":"architecture","stage":"scale","impact":["users"],"severity":{"level":"high","score":8,"financial":"Significant"},"summary":"Research found 51% of cluster-wide failures are caused by interdependencies. Control plane timeout cascades into complete cluster unavailability through autoscaler amplification.","root-cause":"Hidden coupling between control plane and data plane; autoscalers amplify failures by acting on bad health signals; control plane timeouts interpreted as node failures.","lessons":["Implement circuit breaker logic in autoscalers to prevent action on degraded signals","Separate control plane and data plane health monitoring to avoid false positives","Use dependency-aware scaling that understands control plane dependencies","Build observability specifically for interdependency detection"],"patterns":["hidden-single-point-of-failure","cascading-dependency-failure","amplification-in-automation"],"tags":["kubernetes","cascading-failure","control-plane","autoscaler","node-explosion","hidden-dependency"],"sources":["https://github.com/doy2020/mutiny","https://www.usenix.org/conference/fast24/presentation/paper-jiang"],"supporting-entities":["USENIX FAST","Jiang et al.","Kubernetes Community"]}
{"id":"ai-pilots-integration-complexity-2026","title":"AI Pilots Fail Due to Integration Complexity","year":2026,"evidence-type":"repeated-pattern","category":"decision","cause":"incentives","stage":"scale","impact":["money","morale"],"severity":{"level":"high","score":8,"financial":"Pilot investment losses"},"summary":"AI pilots succeed on curated data but fail to scale due to legacy system friction. Integration complexity is the primary blocker for pilot-to-production transitions.","root-cause":"Pilots ignore legacy API unreliability; data format mismatches become fatal at production scale; lack of infrastructure team involvement; false confidence from clean data success.","lessons":["Include infrastructure teams in the pilot phase from day one","Test agents on real production data early, not just curated datasets","Map all integration dependencies before declaring pilot success","Plan for legacy system friction and edge cases in pilot design"],"patterns":["pilot-failure","integration-complexity","scale-failure"],"tags":["pilot-failure","integration-complexity","scale-failure","legacy-systems","ai-deployment"],"sources":["https://www.linkedin.com/pulse/gemini-3-continually-hallucinates-gaslights-face-rag-errors-jesse-vyete"],"supporting-entities":["Composio","Various AI Vendors"]}
